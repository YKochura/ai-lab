{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxImKw1UhQl7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YKochura/ai-lab/blob/main/lab3/logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2XBnP5_Z0pD"
      },
      "source": [
        "**Логістична регресія** &mdash; статистичний регресійний метод, який застосовують для задач бінарної класифікації, тобто, коли модель має віднести вихідне значення (прогноз) до однієї з двох категорій: `0` або `1`.\n",
        "\n",
        "Наприклад, ми можемо за допомогою логістичної регресії передбачити результат складання студентом / студенткою екзамену з цього предмету `{здасть (1) / не здасть (0)}`, використовуючи інформацію про те, скільки часу було витрачено студентом / студенткою на проєкт, скільки лекцій відвідано, скільки практичних здано на оцінку > 7 балів, тощо. Або ж ми можемо за допомогою логістичної моделі класифікувати зображення на дві категорії, наприклад, `кіт (1)` або `собака (0)`.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Lh31rnBI5b"
      },
      "source": [
        "# Модель логістичної регресії\n",
        "\n",
        "Логістичну регресію можна розглядати як одношарову нейронну мережу, яка складається з одного нелінійного нейрона.\n",
        "\n",
        "![](https://docs.google.com/uc?export=download&id=1Abx7cOwNEV0CcFHRVo4XqKMfhgBZeUdS)\n",
        "\n",
        "Метод логістичної регресії заснований на лiнiйнiй регресiї, оскільки використовується однаковий підхід: знаходження лінійної комбінації вхідних ознак (зважена сума) з урахуванням зміщення. Основна віднність між цими методами полягає у тому, що у логістичній регресії до зваженої суми вхідних ознак та зміщення, що фактично є вихідним значенням лінійної регресії, застосовується сигмоїдна функцiя активації, яка перетворює вихiд лiнiйної моделі у вихід логістичної регресії. Іншими словами, вихід (прогноз) логістичної регресії представляє собою дійсне значення, яке лежить у діапазоні вiд 0 до 1 ($\\hat y \\in [0, 1]$). Це значення можна iнтерпретувати як ймовiрнiсть приналежності вхідних даних до певного класу (0 або 1):\n",
        "\n",
        "$$p(y = 1 | z) = \\hat y = \\sigma(z) = g(z) = \\frac{1}{1 + \\exp{(-z)}} $$\n",
        "\n",
        "У випадку, коли нейрон є лінійним, тобто, коли відсутня нелінійна функція активації, тоді на виході отримуємо $\\hat y = z$, що є просто вихідним значення лінійної регресії.\n",
        "\n",
        "## Функції активації\n",
        "Нижче подано деякі загальновживані функції активації (усі нелінійні), які часто використовуються у нейронних мережах.\n",
        "\n",
        "![](https://docs.google.com/uc?export=download&id=1jNGnPUyKH7SoQton8bWAHhmKHkuLtLr4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfQwoDlx-YHi"
      },
      "source": [
        "За характером навчальних даних, метод логістичної регресії відносить до контрольованого навчання (навчання з учителем). Тобто, для кожного прикладу з навчального набору даних заздалегідь підготовлена мітка (label), яка показує приналежніть цих прикладів певного класу.\n",
        "\n",
        "**Дано:**\n",
        "\n",
        "- Навчальний набір: $\\{(\\boldsymbol{X}^{(1)}, y^{(1)}), (\\boldsymbol{X}^{(2)}, y^{(2)}),..., (\\boldsymbol{X}^{(n)}, y^{(n)})\\}$\n",
        "\n",
        "  - де $\\boldsymbol{X}^{(i)}$ &mdash;  $i$-й навчальний приклад. Є $m$-вимірним вектором-стовпцем $\\boldsymbol{X}^{(i)} = (x^{(i)}_1, x^{(i)}_2, ..., x^{(i)}_m)$\n",
        "  - $n$ &mdash; загальна кількість навчальних прикладів\n",
        "  - $y^{(i)}$ &mdash; підготовлена мітка для $i$-го навчального прикладу (бінарна змінна), $y^{(i)} \\in \\{0,1\\}$\n",
        "\n",
        "Модель логістичної регресії можна інтерпретувати як дуже просту нейронну мережу, яка:\n",
        "\n",
        "- має вектор-рядок дійсних значень ваг $\\boldsymbol{W} = \\begin{bmatrix}\n",
        "w_1 & w_2 & \\cdots & w_m\n",
        "\\end{bmatrix}$\n",
        "- має дійсне значення зміщення $b$\n",
        "- використовує сигмоїду в якості активаційної функції"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wtEFeieFmwI"
      },
      "source": [
        "# Навчання\n",
        "\n",
        "Ми можемо навчити модель, використовуючи градієнтний спуск. Фактично, **градієнтний спуск** або будь-який інший алгоритм оптимізації дозволяє знайти глобальний мінімум цільової функції (усередненої функції втрат на всьому навчальному наборі), якщо підбрано оптимальну швидкість навчання та виконано достатню кількість ітерацій навчання.\n",
        "\n",
        "Навчання моделі логістичної регресії має різні етапи. На початку (крок 0) ініціалізуються параметри моделі. Інші кроки повторюються протягом певної кількості епох (навчальних ітерацій).\n",
        "\n",
        "**Крок 0:** Ініціалізувати ваги та зсув (наприклад, випадковими значеннями з нормального розподілу)\n",
        "\n",
        "**Крок 1:** Обчислити лінійну комбінацію вхідних ознак та ваг, включаючи зсув.  Це можна зробити за один крок для всіх навчальних прикладів, використовуючи [векторизацію (vectorization)](https://www.geeksforgeeks.org/vectorization-in-python/) та  [трансляцію (broadcasting)](https://www.geeksforgeeks.org/python-broadcasting-with-numpy-arrays/)\n",
        "\n",
        "$$z = W \\cdot X + b$$\n",
        "\n",
        "де $\\cdot$ скалярний добуток (поелементний добуток), $W$ &mdash;  вектор-рядок ваг з формою $(1, m)$, $X$ &mdash; матриця форми $(m, n)$.\n",
        "\n",
        "**Крок 2:** Застосувати нелінійну функцію активації (сигмоїду), яка поверне дійсне значення у проміжку між 0 та 1:\n",
        "\n",
        "$$\\hat y  = \\frac{1}{1 + \\exp(-z)}$$\n",
        "\n",
        "**Крок 3:** Обчислити усереднену втрату на всьому навчальному наборі даних. Функцію, яка визначає усереднені втрати на всьому навчальному наборі даних, часто називають цільовою функцією або імпіричним ризиком. Основна задача оптимізаційного алгоритму &mdash;  мінімізувати у процесі навчання цільову функцію на стільки, на скільки це можливо, не втрачаючи при цьому здатності моделі узагальнювати на нових даних. Для задач бінарної класифікації використовують бінарну перехресну втрату ентропії:\n",
        "\n",
        "$$\\mathcal{J}(\\hat y,y)  = - \\frac{1}{n} \\sum_{i=1}^n \\Big[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\Big]$$\n",
        "\n",
        "**Крок 4:** Розрахувати градієнти цільвої функції відносно ваг та зсуву:\n",
        "\n",
        "$$\\boxed{\\begin{aligned}\n",
        "\\frac{\\partial \\mathcal{J}(\\hat y, y)}{\\partial \\hat y} &= \\frac{1}{n} \\big [-\\frac{y}{\\hat y} + \\frac{1- y}{1 - \\hat y} \\big ] \\\\[12pt]\n",
        "\\frac{\\partial \\mathcal{J}(\\hat y, y)}{\\partial z} &= \\frac{\\partial \\mathcal{J}(\\hat y, y)}{\\partial \\hat y} \\frac{\\partial \\hat y}{\\partial z} = \\frac{1}{n} (\\hat y - y)  \\\\[12pt]\n",
        "\\frac{\\partial \\mathcal{J}(\\hat y, y)}{\\partial W} &= \\frac{\\partial \\mathcal{J}(\\hat y, y)}{\\partial \\hat y} \\frac{\\partial \\hat y}{\\partial z} \\frac{\\partial z}{\\partial W} = \\frac{1}{n} X^\\intercal \\cdot (\\hat y - y) \\\\[12pt]\n",
        "\\frac{\\partial \\mathcal{J}(\\hat y, y)}{\\partial b} &=  \\frac{\\partial \\mathcal{J}(\\hat y, y)}{\\partial \\hat y} \\frac{\\partial \\hat y}{\\partial z} \\frac{\\partial z}{\\partial b} = \\frac{1}{n} (\\hat y - y)\n",
        "\\end{aligned}}$$\n",
        "\n",
        "**Крок 5:** Оновити ваги та зсув:\n",
        "\n",
        "$$\\boxed{\\begin{aligned}\n",
        "W &= W - \\alpha \\frac{\\partial \\mathcal{L}(\\hat y, y)}{\\partial W} \\\\[12pt]\n",
        "b &= b - \\alpha \\frac{\\partial \\mathcal{L}(\\hat y, y)}{\\partial b}\n",
        "\\end{aligned}}$$\n",
        "\n",
        "де $\\alpha$ &mdash; швидкість навчання (крок навчання)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU31wxOL_iBb"
      },
      "source": [
        "# Імпортупвання бібліотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19xicNjUYyKR"
      },
      "source": [
        "import numpy as np # numerical python library for calculus\n",
        "from PIL import Image # image processing in python with Pillow\n",
        "import requests # library for obtaining the requested data from the specific server\n",
        "from matplotlib import pyplot as plt # library for creating static, animated, and interactive visualizations in Python\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(1) # makes the random numbers predictable"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завантажєння датасету та [breast_cancer](https://scikit-learn.org/0.21/modules/generated/sklearn.datasets.load_breast_cancer.html) та перегляд повного опису набору"
      ],
      "metadata": {
        "id": "ndsLjCZEAyeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = datasets.load_breast_cancer()\n",
        "print(df.DESCR)"
      ],
      "metadata": {
        "id": "FQBdRiq--0Pe",
        "outputId": "691dc4b8-9313-414f-b817-4ff6677123aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry\n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        worst/largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
            "        10 is Radius SE, field 20 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ознаки"
      ],
      "metadata": {
        "id": "Q1ybT_YvBIa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(df.feature_names)"
      ],
      "metadata": {
        "id": "s6GmKVuH_7_q",
        "outputId": "2f04ed20-110c-47c6-b605-1b07bcb7c4b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mean radius',\n",
              " 'mean texture',\n",
              " 'mean perimeter',\n",
              " 'mean area',\n",
              " 'mean smoothness',\n",
              " 'mean compactness',\n",
              " 'mean concavity',\n",
              " 'mean concave points',\n",
              " 'mean symmetry',\n",
              " 'mean fractal dimension',\n",
              " 'radius error',\n",
              " 'texture error',\n",
              " 'perimeter error',\n",
              " 'area error',\n",
              " 'smoothness error',\n",
              " 'compactness error',\n",
              " 'concavity error',\n",
              " 'concave points error',\n",
              " 'symmetry error',\n",
              " 'fractal dimension error',\n",
              " 'worst radius',\n",
              " 'worst texture',\n",
              " 'worst perimeter',\n",
              " 'worst area',\n",
              " 'worst smoothness',\n",
              " 'worst compactness',\n",
              " 'worst concavity',\n",
              " 'worst concave points',\n",
              " 'worst symmetry',\n",
              " 'worst fractal dimension']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Мітки"
      ],
      "metadata": {
        "id": "FTnuRJjrBRcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(df.target_names)"
      ],
      "metadata": {
        "id": "dFrpydLk_QBI",
        "outputId": "8b203b3f-7d2f-48c1-82fa-43b7e498bf80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['malignant', 'benign']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = {0 : 'malignant', 1 : 'benign'}"
      ],
      "metadata": {
        "id": "EcDwAoYsAJsP"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Перегляд міток для кількох прикладів з набору"
      ],
      "metadata": {
        "id": "RKyifp88BZrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.target[[0, 10, 90]]"
      ],
      "metadata": {
        "id": "MIK5xgKSAZqd",
        "outputId": "b5b45d83-9099-4f13-fc5b-bc51e3a53276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[classes[i] for i in df.target[[0, 10, 90]]]"
      ],
      "metadata": {
        "id": "BhymhteOAj6k",
        "outputId": "e69254d5-89e1-4d4b-c6eb-fdc079e2f1d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['malignant', 'malignant', 'benign']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPLwu0rWaCeJ"
      },
      "source": [
        "---\n",
        "# Завдання\n",
        "\n",
        "Розглянемо задачу бінарної класифікації зображень: кіт (1) або собака (0). Оскільки на нашому зображенні, яке ми будемо використовувати у якості навчального прикладу для логістичної регресії знаходиться собака, створимо відповідну мітку:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpq48noEKJgY"
      },
      "source": [
        "### Крок 0: Ініціалізувати ваги та зсув"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfkqaTCL27hF"
      },
      "source": [
        "# TODO\n",
        "def parameters_inititalization(m):\n",
        "  \"\"\"\n",
        "  Ця функція ініціалізує вектор-рядок випадкових дійсних значень ваг форми (1, m), отриманих з нормального розподілу та зсув (довільне дійсне значення)\n",
        "\n",
        "  Параметри:\n",
        "  m -- кількість вхідних ознак для кожного навчального прикладу\n",
        "\n",
        "  Повертає:\n",
        "  W -- вектор-рядок ваг форми (1, 50310)\n",
        "  b -- зсув (скаляр)\n",
        "  \"\"\"\n",
        "\n",
        "  # BEGIN_YOUR_CODE\n",
        "  raise Exception(\"Not implemented yet\")\n",
        "  # END_YOUR_CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjoi0Pi0eIl9"
      },
      "source": [
        "W, b = parameters_inititalization()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_nNfaRGdLGO"
      },
      "source": [
        "W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVUfQgU3dRoj"
      },
      "source": [
        "W.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGyt_i05dT_r",
        "outputId": "5a7b36c2-9a1a-4880-cb67-15ab6de3a643"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMLPcw7gNZ1d"
      },
      "source": [
        "## Крок 1 та 2\n",
        "\n",
        "### Крок 1: Обчислити лінійну комбінацію вхідних ознак та ваг, включаючи зсув\n",
        "\n",
        "### Крок 2: Застосувати нелінійну функцію активації (сигмоїду) до отриманого значення з крок 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHg5Sh8bdV3J"
      },
      "source": [
        "# TODO\n",
        "def forwardPropagate(X, W, b):\n",
        "  \"\"\"\n",
        "  Ця функція обчислює лінійну комбінацію вхідних ознак та ваг, включаючи зсув і знаходить активаційне значення сигмоїди\n",
        "\n",
        "  Параметри:\n",
        "  X -- вхідний вектор стовпець (у нашому випадку - це чорнобіле зображення собаки) форми (50310, 1)\n",
        "  W -- вектор-рядок ваг моделі форми (1, 50310)\n",
        "  b -- зсув моделі (скаляр)\n",
        "\n",
        "  Повертає:\n",
        "  z -- загальна зважена сума вхідних ознак, включаючи зсув\n",
        "  y_hat -- активаційне значення сигмоїди\n",
        "  \"\"\"\n",
        "\n",
        "  # BEGIN_YOUR_CODE\n",
        "  raise Exception(\"Not implemented yet\")\n",
        "  # END_YOUR_CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94IMy1_2dfuQ"
      },
      "source": [
        "z, y_hat = forwardPropagate(norm, W, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF67K5RJiEux"
      },
      "source": [
        "z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8urwc6qKiFQQ"
      },
      "source": [
        "y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1L7RqCHOShJ"
      },
      "source": [
        "### Крок 3: Обчислити усереднену втрату на всьому навчальному наборі даних. Цільова функція\n",
        "\n",
        "У нашому випадку ми розглядаємо пряме та зворотне поширення для одного навчального прикладу (зображення)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM5DZaGIl-ei"
      },
      "source": [
        "# TODO\n",
        "def cost(n, y_hat, y_true):\n",
        "  \"\"\"\n",
        "  Ця функція обчислює усереднену втрату для задачі бінарної класифікації на всьому навчальному наборі даних\n",
        "\n",
        "  Параметри:\n",
        "  n -- загальна кількість навчальних прикладів (у нашому випадку - це  одне чорнобіле зображення собаки)\n",
        "  y_hat -- активаційне значення сигмоїди (прогноз логістичної регресії)\n",
        "  y_true -- істинний клас зображення (очікувана мітка прогнозу)\n",
        "\n",
        "  Повертає:\n",
        "  J --  усереднена втрата моделі для задачі бінарної класифікації на всьому навчальному наборі даних\n",
        "  \"\"\"\n",
        "\n",
        "  # BEGIN_YOUR_CODE\n",
        "  raise Exception(\"Not implemented yet\")\n",
        "  # END_YOUR_CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVuroIbum_4L"
      },
      "source": [
        "J = cost(1, y_hat, y_true)\n",
        "J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bapG8TtdP4gK"
      },
      "source": [
        "### Крок 4: Розрахувати градієнти цільвої функції відносно ваг та зсуву"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K-Vn0mpiGng"
      },
      "source": [
        "# TODO\n",
        "def backwardPropagate(n, X, y_hat, y_true):\n",
        "  \"\"\"\n",
        "  Ця функція обчислює градієнти цільвої функції відносно ваг та зсуву\n",
        "\n",
        "  Параметри:\n",
        "  n -- загальна кількість навчальних прикладів (у нашому випадку - це  одне чорнобіле зображення собаки)\n",
        "  X -- вхідний вектор стовпець (у нашому випадку - це чорнобіле зображення собаки) форми (50310, 1)\n",
        "  y_hat -- активаційне значення сигмоїди (прогноз логістичної регресії)\n",
        "  y_true -- істинний клас зображення (очікувана мітка прогнозу)\n",
        "\n",
        "  Повертає:\n",
        "  dW --  градієнт цільової функції відносно ваг моделі\n",
        "  db -- градієнт цільової функції відносно зсуву моделі\n",
        "  \"\"\"\n",
        "\n",
        "  # BEGIN_YOUR_CODE\n",
        "  raise Exception(\"Not implemented yet\")\n",
        "  # END_YOUR_CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VirkpmD0o-1Q"
      },
      "source": [
        "dW, db = backwardPropagate(1, norm, y_hat, y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLjgo0GdpMx0"
      },
      "source": [
        "dW.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZBTCeXdqFJA"
      },
      "source": [
        "db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAkVSaLesD_8"
      },
      "source": [
        "db.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wzrFBQPSfL5"
      },
      "source": [
        "### Крок 5: Оновити ваги та зсув"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwacLBbFsKHZ"
      },
      "source": [
        "# TODO\n",
        "def update(alpha, dW, db, W, b):\n",
        "  \"\"\"\n",
        "  Ця функція оновлює навчальні параметри моделі (ваги та зсув ) у напрямку мінімізації цільової функції\n",
        "\n",
        "  Параметри:\n",
        "  alpha -- швидкість  навчання (крок навчання)\n",
        "  dW --  градієнт цільової функції відносно ваг моделі\n",
        "  db -- градієнт цільової функції відносно зсуву моделі\n",
        "  W -- вектор-рядок ваг моделі форми (1, 50310)\n",
        "  b -- зсув моделі (скаляр)\n",
        "\n",
        "  Повертає:\n",
        "  W -- оновлений вектор-рядок ваг моделі форми (1, 50310)\n",
        "  b -- оновлений зсув моделі (скаляр)\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # BEGIN_YOUR_CODE\n",
        "  raise Exception(\"Not implemented yet\")\n",
        "  # END_YOUR_CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f-dOng9tKRy"
      },
      "source": [
        "W, b = update(0.0001, dW, db, W, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X681Y8JatVAi"
      },
      "source": [
        "W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWrWtkXhtWl4"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}